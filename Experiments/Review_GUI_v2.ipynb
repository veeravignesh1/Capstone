{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Packages\n",
    "import os\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tkinter import *\n",
    "from tkinter import filedialog, messagebox\n",
    "#import tkinter.messagebox\n",
    "from PIL import ImageTk,Image\n",
    "#NLP imports\n",
    "#import nltk\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import SentenceSegmenter\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "# VaderSentiment is used for splitting reviews into positive and negative sentiments\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "#Ignoring Errors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Creating a window in tkinter making it of fixed width and non-resizeable\n",
    "window = tk.Tk()\n",
    "window.geometry(\"600x400\")\n",
    "window.resizable(0,0)\n",
    "window.title(\"Rank Reviews\")\n",
    "window.configure(bg='white')\n",
    "# Changing the icon\n",
    "#window.iconbitmap('favicon.ico')\n",
    "\n",
    "#Declaring Tkinter Variables\n",
    "entryfile=tk.StringVar()\n",
    "folderpath=tk.StringVar()\n",
    "\n",
    "#Select File Name Function\n",
    "def selectfilename():\n",
    "    global filename\n",
    "    filename=tk.filedialog.askopenfilename(initialdir=os.getcwd())\n",
    "    print(filename)\n",
    "    entryfile.set(filename)\n",
    "\n",
    "# #Location to save Function\n",
    "# def selectfolder():\n",
    "#     global foldername\n",
    "#     foldername=tk.filedialog.askdirectory(initialdir=os.getcwd())\n",
    "#     print(foldername)\n",
    "#     folderpath.set(foldername)\n",
    "\n",
    "#Submit Button Function Command\n",
    "def submit():\n",
    "    if len(file_entry.get()) == 0:\n",
    "        tk.messagebox.showerror(\"Error!\", \"No file mentioned\")\n",
    "\n",
    "    else:\n",
    "        data=filename\n",
    "        print(data)\n",
    "#     directory=foldername\n",
    "#     print(directory)\n",
    "        rank(data,save=None)\n",
    "        done.config(text=\"Reviews Ranked and Stored in specified directory\")\n",
    "    #rank(data,save=None)\n",
    "    #done.config(text=\"Reviews Ranked and Stored in specified directory\")\n",
    "\n",
    "#All Sub function of Rank --> To create features\n",
    "\n",
    "# VADER sentiment analysis tool for getting pos, neg and neu.\n",
    "# VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "def sentimental_Score(sentence):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    score=vs['compound']\n",
    "    if score >= 0.5:\n",
    "        return 'pos'\n",
    "    elif (score > -0.5) and (score < 0.5):\n",
    "        return 'neu'\n",
    "    elif score <= -0.5:\n",
    "        return 'neg'\n",
    "\n",
    "# Create Target\n",
    "def target(df):\n",
    "    df['h']=np.round(df.Upvote/(df.Upvote+df.Downvote),2)\n",
    "    return df\n",
    "\n",
    "#Dropping Unwanted Columns\n",
    "def drop_cols(df):\n",
    "    drop=[\"Sum_of_Up_Down\",\"Upvote\",\"Downvote\"]\n",
    "    df=df.drop(drop,axis=1)\n",
    "    return df\n",
    "\n",
    "# Number of Sentence\n",
    "def num_sentence(text):\n",
    "    #return len(nltk.sent_tokenize(text))\n",
    "    doc = nlp(text)\n",
    "    return len(list(doc.sents))\n",
    "\n",
    "# Number of Upper case words (Fully Upper)\n",
    "def count_upper(text):\n",
    "    count=0\n",
    "    for i in text.split():\n",
    "        if text.isupper():\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "# Number of words with Proper Format\n",
    "def count_proper(text):\n",
    "    count=0\n",
    "    for i in text.split():\n",
    "        if text.istitle():\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "#Number of Emoji\n",
    "def emoji_count(text):\n",
    "    return emoji.emoji_count(text)\n",
    "\n",
    "#Remove emoji from review Text\n",
    "def remove_emoji(text):\n",
    "    return text.encode('ascii','ignore').decode('ascii').strip()\n",
    "\n",
    "#Remove Punctuations\n",
    "def remove_punctuations(text):\n",
    "    return re.sub('[^\\w\\s%,-.]',\"\",text).strip()\n",
    "\n",
    "#Add POS tag for each word\n",
    "def pos_tag(text):\n",
    "    doc=nlp(text)\n",
    "    return ' '.join([token.pos_ for token in doc])\n",
    "\n",
    "#Percentage of Nouns\n",
    "def Noun(text):\n",
    "    text_len=len(text.split())\n",
    "    noun_count=0\n",
    "    for word in text.split():\n",
    "        if word=='NOUN':\n",
    "            noun_count+=1\n",
    "    return np.round((noun_count/text_len)*100,2)\n",
    "\n",
    "#Percentage of Verb\n",
    "def Verb(text):\n",
    "    text_len=len(text.split())\n",
    "    verb_count=0\n",
    "    for word in text.split():\n",
    "        if word=='VERB':\n",
    "            verb_count+=1\n",
    "    return np.round((verb_count/text_len)*100,2)\n",
    "\n",
    "#Percentage of Adverb\n",
    "def Adverb(text):\n",
    "    text_len=len(text.split())\n",
    "    adv_count=0\n",
    "    for word in text.split():\n",
    "        if word=='ADV':\n",
    "            adv_count+=1\n",
    "    return np.round((adv_count/text_len)*100,2)\n",
    "\n",
    "#Percentage of Adjective\n",
    "def Adj(text):\n",
    "    text_len=len(text.split())\n",
    "    adj_count=0\n",
    "    for word in text.split():\n",
    "        if word=='ADJ':\n",
    "            adj_count+=1\n",
    "    return np.round((adj_count/text_len)*100,2)\n",
    "\n",
    "#Creates features for the current df\n",
    "def features(df):    \n",
    "    #Filtering Reviews which has Sum of Upvote and Downvote which is greater than 10\n",
    "    df['Sum_of_Up_Down']=df.Upvote-df.Downvote\n",
    "    df=df[df.Sum_of_Up_Down>10]\n",
    "\n",
    "    #Adding New Sentiment Column by calling the function **sentimental_Score**\n",
    "    df['Sentiment'] = df.Review_Text.apply(sentimental_Score)\n",
    "    #Creating target and dropping unwanted columns \n",
    "    df=target(df)\n",
    "    df=drop_cols(df)\n",
    "    \n",
    "    #Length Before\n",
    "    df[\"Len_before\"] = df.Review_Text.apply(lambda x: len(x.split()))\n",
    "\n",
    "    #Creating Num_Sentence\n",
    "    df['Num_Sentence']=df.Review_Text.apply(num_sentence)\n",
    "\n",
    "    #Number of Question Mark\n",
    "    df['No_QMark'] = df.Review_Text.str.count(pat='\\?')\n",
    "\n",
    "    #Number of Exclamatio Mark\n",
    "    df['No_ExMark']=df.Review_Text.str.count(pat='!')\n",
    "\n",
    "    #Number of Upper Case Text\n",
    "    df['No_Upper']=df.Review_Text.apply(count_upper)\n",
    "\n",
    "    #Number of Proper Case Text\n",
    "    df['No_proper']=df.Review_Text.apply(count_proper)\n",
    "\n",
    "    #Count of Emoji\n",
    "    df['Emoji_Count']=df.Review_Text.apply(emoji_count)\n",
    "\n",
    "    #Handling Emoji in review_text\n",
    "    df['Review_Text']=df.Review_Text.apply(remove_emoji)\n",
    "\n",
    "    #Remove Punctuations\n",
    "    df.Review_Text=df.Review_Text.apply(remove_punctuations)\n",
    "\n",
    "    #Removed spell correction because its taking time in TextBlob\n",
    "\n",
    "    #Apply Lemmatization for the review and remove stop words\n",
    "    df.Review_Text=df.Review_Text.apply(lambda text: \" \".join(token.lemma_ for token in nlp(text) \n",
    "                                               if not token.is_stop)) \n",
    "\n",
    "    #Length of the Review After removing stop words\n",
    "    df[\"Len_after\"] = df.Review_Text.apply(lambda x: len(x.split()))\n",
    "\n",
    "    #Applying POS for all words\n",
    "    df['POS']=df.Review_Text.apply(pos_tag)\n",
    "\n",
    "    #To avoid Zero Division Error\n",
    "    df=df[df.Len_after>=1]\n",
    "\n",
    "    #Percentage of Noun\n",
    "    df['Perc_Noun']=df.POS.apply(Noun)\n",
    "\n",
    "    #Percentage of Verb\n",
    "    df['Perc_Verb']=df.POS.apply(Verb)\n",
    "\n",
    "    #Percentage of Adverb\n",
    "    df['Perc_Adverb']=df.POS.apply(Adverb)\n",
    "\n",
    "    #Percentage of Adjective\n",
    "    df['Perc_Adj']=df.POS.apply(Adj)\n",
    "    \n",
    "    return df\n",
    "def predictor(df,n=1):\n",
    "    '''\n",
    "    Pass the df for which important features with tfidf is needed\n",
    "    n represents the percentage of document in which it should occur or else its neglected as important feature\n",
    "    '''\n",
    "    count=CountVectorizer(token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "    count_matrix=count.fit_transform(df.Review_Text)\n",
    "    bow=pd.DataFrame(count_matrix.toarray(),columns=count.get_feature_names())\n",
    "    bow_sum=pd.DataFrame(bow.sum(axis=0),columns=['sum_count'])\n",
    "\n",
    "    #getting the column names of words which occured more than 1 of the times in the entire corpus\n",
    "    important = list(bow_sum[bow_sum.sum_count>len(df)*n/100].index)\n",
    "\n",
    "    tfidf= TfidfVectorizer(token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "    Matrix=tfidf.fit_transform(df.Review_Text)\n",
    "    unigram=pd.DataFrame(Matrix.toarray(),columns=tfidf.get_feature_names())\n",
    "    unigram=unigram[important]\n",
    "    df=df.drop(['Review_Title','Review_Text','POS','Sentiment'],axis=1)\n",
    "    main=unigram.join(df)\n",
    "    main=main.fillna(0)\n",
    "    X=main.drop('h',axis=1)\n",
    "    y=main.h\n",
    "    return X,y\n",
    "    \n",
    "#Main Ranking Function\n",
    "def rank(data,save=None):\n",
    "    '''\n",
    "    rank function takes in csv file with `review title`, `review text`, `review rating`,`upvote`\n",
    "    and `downvote` as an input and ranks the review based on the important unigrams in the corpus and \n",
    "    other features and stores it in the user specified path\n",
    "    '''\n",
    "\n",
    "    # Setting directory to current directory if No value is provided\n",
    "    if save == None:\n",
    "        save = os.getcwd()\n",
    "\n",
    "    # Get the file type and filename from data\n",
    "    filename = data[:data.find('.')]\n",
    "    print(filename)\n",
    "    filetype = data[data.find('.')+1:]\n",
    "    print(filetype)\n",
    "    phone = data[data.rfind('/')+1:data.find('.')]\n",
    "    # Make directory in the filename and change cwd to that folder to store all data in that\n",
    "    # Handling Removing of empty directory in the name of filename\n",
    "    if filename not in os.listdir(save):\n",
    "        os.mkdir(save+'\\\\'+phone)\n",
    "    else:\n",
    "        os.removedirs(save+'\\\\'+phone)\n",
    "        os.mkdir(save+'\\\\'+phone)\n",
    "\n",
    "    # Combining file types to call relevant read function\n",
    "    \n",
    "\n",
    "    # Evaluating the file based on the filename provided and storing it in the dataframe\n",
    "    # Handling multiple file types\n",
    "    try:\n",
    "        if filetype=='xlsx' or filetype == 'xls':\n",
    "            df = pd.read_excel(filename+'.'+filetype)\n",
    "        else:\n",
    "            read = \"pd.read_\"+filetype\n",
    "            #print(data)\n",
    "            df = eval(read)(data)\n",
    "    except AttributeError as ae:\n",
    "        print(ae)\n",
    "        print(entryfile)\n",
    "        df = pd.read_csv(filename+'.'+filetype)\n",
    "    \n",
    "    # Changing directory to save all graph\n",
    "    os.chdir(save+'\\\\'+phone)\n",
    "    \n",
    "    #Add in the code here\n",
    "    df = features(df)\n",
    "    X,y = predictor(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=50,random_state=0)\n",
    "    xgb = XGBRegressor(n_estimators = 1000,n_jobs=-1,random_state = 0)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    # Predicting on test data\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    X_test= pd.DataFrame(X_test)\n",
    "    X_test['h_pred']=y_pred\n",
    "    #df['h_pred']=xgb.predict(X)\n",
    "    X_test=X_test.sort_values(by='h_pred',ascending=False) \n",
    "    \n",
    "    X_test.to_csv(\"allreviews.csv\")\n",
    "    X_test[X_test.Sentiment=='pos'].to_csv(\"positive.csv\")\n",
    "    X_test[X_test.Sentiment=='neg'].to_csv(\"negative.csv\")\n",
    "    \n",
    "    # Changing directory to parent\n",
    "    os.chdir('..')\n",
    "\n",
    "#TITLE FRAME\n",
    "top_frame = tk.Frame(master=window, height=60, background=\"aqua\",bd=1)\n",
    "top_frame.pack(fill='x',padx=5,pady=5)\n",
    "\n",
    "#Top Label\n",
    "top_label = tk.Label(master=top_frame,text=\"Review Ranking System\",font=(\"Times\",25),bg=\"aqua\",fg=\"black\").pack()\n",
    "\n",
    "#MIDDLE FRAME\n",
    "mid_frame = tk.Frame(master=window,height = 320,bg='white')\n",
    "mid_frame.pack(fill=\"both\",padx=5,pady=5)\n",
    "\n",
    "#Mid Labels\n",
    "\n",
    "#file and path of file\n",
    "file = tk.Label(master=mid_frame,text=\"File: \",font=(\"Times\",14),bg='white',fg=\"black\")\n",
    "file.place(x=25,y=50)\n",
    "\n",
    "#Entry field to paste the directory of the file\n",
    "file_entry = tk.Entry(master=mid_frame,textvariable=entryfile,width=70,bg='white',fg=\"black\",borderwidth=2)\n",
    "file_entry.place(x=75,y=55)\n",
    "\n",
    "#Select File Button:\n",
    "# select = tk.Button(master = mid_frame, text=\"Select\", command=select)\n",
    "select = filedialog.Button(master = mid_frame, text=\"Browse\", font=('Times', 10, 'bold'), command=selectfilename,bg='white',fg=\"black\",borderwidth=2)\n",
    "select.place(x=515,y=52)\n",
    "\n",
    "#Location to save the graph\n",
    "# location=tk.Label(master=mid_frame,text=\"Location to save: \",font=(\"Times\",15)).place(x=40,y=150)\n",
    "\n",
    "#Select Location Button\n",
    "# select2 = filedialog.Button(master = mid_frame, text=\"Select\", command=selectfolder).place(x=520,y=150)\n",
    "\n",
    "#Folder to save in...\n",
    "# file_entry = tk.Entry(master=mid_frame,textvariable=folderpath,width=50).place(x=200,y=154)\n",
    "\n",
    "label = tk.Label(text=\"Note: \", font=('Times', 12, 'bold'),bg='white',fg=\"black\")\n",
    "label.place(x=55,y=200)\n",
    "label1 = tk.Label(text=\"The file should contain the following columns in the specified order:\\n`Review_Title`, `Review_Text`,\\\n",
    "`Review_Rating`,`Upvote` and `Downvote`.\",font=('Times', 12),bg='white',fg=\"black\")\n",
    "label1.place(x=70,y=220)\n",
    "\n",
    "#Submit Button\n",
    "submit = tk.Button(master=mid_frame,text=\"Submit\",font=('Times', 11, 'bold'),command=submit,bg='white',fg=\"black\",borderwidth=2)\n",
    "submit.place(x=255,y=250)\n",
    "\n",
    "#result\n",
    "done = tk.Label(master=mid_frame,text=\"\",bg='white',fg=\"black\")\n",
    "done.place(x=200,y=280)\n",
    "    \n",
    "tk.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
